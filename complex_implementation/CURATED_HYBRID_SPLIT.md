# Curated Hybrid Split - Quick Reference

## ğŸ¯ What is it?

A **hybrid data splitting strategy** that balances clinical validity with class balance:

- **Test Set:** Pure patient-wise (held-out patients, no leakage) âœ…
- **Train/Val Sets:** Beat-wise pooling (shares patients for class balance) âš ï¸

## ğŸ”¬ Why Use It?

### **Problem it Solves:**
```
Standard Patient-wise Split:
  âŒ Rare classes (Fusion, Unknown) often missing from test set
  âŒ Class imbalance makes evaluation incomplete
  âœ… But: Valid generalization (patient-wise)

Beat-wise Split:
  âœ… Perfect class balance
  âŒ Data leakage (invalid generalization)
  âŒ Not publishable

Curated Hybrid:
  âœ… All classes in test set (curated patients)
  âœ… Valid test generalization (patient-wise test)
  âœ… Better train/val balance (beat pooling)
  âš ï¸  Train/val share patients (acceptable for tuning)
```

## ğŸ“‹ How to Use

### **Step 1: Find Diverse Test Patients**

```bash
cd complex_implementation
python analyze_patient_diversity.py
```

**Output:**
```
TOP 15 MOST DIVERSE PATIENTS
========================================
1. Patient 207
   Classes present: 5/6
   Total beats: 2,500
   - Normal (80%), Ventricular (10%), Fusion (3%), 
     Paced (5%), Unknown (2%)

2. Patient 217
   Classes present: 4/6
   ...
```

**Suggested test patients:** 207, 217

---

### **Step 2: Check Distribution (Optional)**

```bash
python check_split_distribution.py --curated_test 207 217
```

**Shows:**
- Test: Only patients 207, 217 (all classes represented)
- Train: ~85% of beats from remaining 46 patients
- Val: ~15% of beats from remaining 46 patients

---

### **Step 3: Train with Curated Test Set**

```bash
python train.py --model simple_cnn --curated_test 207 217 --epochs 20
```

**Additional options:**
```bash
# With class weights
python train.py --model simple_cnn --curated_test 207 217 --class_weights

# With focal loss
python train.py --model simple_cnn --curated_test 207 217 --focal_loss --focal_gamma 2.0

# Complex model
python train.py --model complex_cnn --curated_test 207 217 --epochs 50
```

---

### **Step 4: Results**

Checkpoints saved to:
```
checkpoints/simple_cnn_YYYYMMDD_HHMMSS_curated_hybrid/
â”œâ”€â”€ config.json          # Includes test_patients: ["207", "217"]
â”œâ”€â”€ SUMMARY.txt          # Documents split strategy
â”œâ”€â”€ best_model.pth       # Best model weights
â”œâ”€â”€ training_history.csv # Epoch-wise metrics
â”œâ”€â”€ training_curves.png  # Loss/accuracy plots
â””â”€â”€ confusion_matrix.png # Test set confusion matrix
```

## ğŸ“Š Expected Results

### **Compared to Patient-wise Stratified:**

| Metric | Patient-wise Stratified | Curated Hybrid |
|--------|------------------------|----------------|
| Test Accuracy | ~90% | ~88-92% |
| Fusion F1 | 0.00 (no samples) | 0.60-0.80 âœ… |
| Unknown F1 | 0.00 (missing) | 0.40-0.60 âœ… |
| Ventricular F1 | 0.54 | 0.65-0.85 |
| **All classes evaluated** | âŒ No | âœ… Yes |
| **Valid generalization** | âœ… Yes | âœ… Yes |

## ğŸ“ How to Report This

### **In Your Paper/Presentation:**

```markdown
## Methodology

We employ a curated patient-wise split to ensure comprehensive 
class coverage while maintaining generalization validity:

1. **Test Set:** Two patients (207, 217) with diverse arrhythmia 
   types were held out completely, ensuring all 6 classes are 
   represented in testing.

2. **Train/Validation:** Remaining 46 patients were used with 
   beat-level splitting (85/15) to ensure class balance for 
   effective model optimization.

**Note:** The test set maintains strict patient separation, 
ensuring reported accuracy reflects true generalization to 
unseen patients. Train/val sets share patients for class 
balance, which is acceptable as validation is used only for 
model selection, not performance claims.

## Results

**Test Accuracy (on held-out patients 207, 217): 88.5%**
- Tests generalization to new patients âœ…
- All arrhythmia classes evaluated âœ…
- No data leakage in test set âœ…
```

## âš ï¸ Important Notes

### **Be Transparent:**

1. **Train/Val Leakage:**
   - "Training and validation sets share patients (for class balance)"
   - "Validation used only for model selection, not performance claims"

2. **Test Purity:**
   - "Test set consists of completely held-out patients"
   - "Test accuracy represents true generalization performance"

3. **Justification:**
   - "Due to rare class clustering in specific patients"
   - "Ensures all arrhythmia types can be fairly evaluated"

### **What's Valid:**
- âœ… Test accuracy as generalization metric
- âœ… Test F1-scores for all classes
- âœ… Test confusion matrix
- âœ… Claiming "generalization to new patients"

### **What's NOT Valid:**
- âŒ Using validation accuracy as final metric
- âŒ Claiming no data leakage anywhere
- âŒ Ignoring train/val patient overlap

## ğŸ”„ Alternative: K-Fold Cross-Validation

For even more robust results:

```bash
# Run 5 times with different test patients
python train.py --curated_test 207 217 --seed 42
python train.py --curated_test 100 106 --seed 43
python train.py --curated_test 119 124 --seed 44
python train.py --curated_test 209 215 --seed 45
python train.py --curated_test 223 230 --seed 46

# Average results across all folds
```

**Report:** "Mean test accuracy: 89.2% Â± 2.1% (5-fold patient-wise cross-validation)"

## ğŸ“ Advanced Options

### **Find More Test Patients:**
```bash
# Find top 20 diverse patients
python analyze_patient_diversity.py --top_n 20

# Suggest 3 test patients
python analyze_patient_diversity.py --num_test_patients 3
```

### **Custom Train/Val Ratios:**
```bash
# 90% train, 10% val from pooled beats
python train.py --curated_test 207 217 --train_ratio 0.675 --val_ratio 0.075
# (0.675 + 0.075 = 0.75, the remaining after holding out test patients)
```

## ğŸ“š References

- `analyze_patient_diversity.py` - Find diverse patients
- `check_split_distribution.py` - Verify class distribution
- `train.py` - Main training script
- `dataset.py` - Data loading and splitting

## ğŸ†š Comparison with Other Methods

| Method | Test Valid? | All Classes? | Use Case |
|--------|-------------|--------------|----------|
| **Patient-wise** | âœ… | âŒ Often missing | Production (if classes covered) |
| **Patient-wise Stratified** | âœ… | âš ï¸ Sometimes missing | Production (better balance) |
| **Beat-wise** | âŒ | âœ… | Prototyping only (leakage) |
| **Curated Hybrid** | âœ… | âœ… | Production (guaranteed coverage) |
| **K-Fold Curated** | âœ…âœ… | âœ… | Research (most robust) |

---

## ğŸ’¡ Bottom Line

**Use curated hybrid when:**
- âœ… You need all classes in test set
- âœ… Rare classes cluster in specific patients
- âœ… Test validity is critical
- âœ… You can justify train/val leakage (tuning only)

**Don't use when:**
- âŒ You can get good balance with regular patient-wise split
- âŒ You have many patients with diverse classes
- âŒ Reviewers won't accept train/val overlap

---

*For questions or issues, refer to `CLASS_DISTRIBUTION.md` and `CLASS_IMBALANCE_SOLUTIONS.md`*

